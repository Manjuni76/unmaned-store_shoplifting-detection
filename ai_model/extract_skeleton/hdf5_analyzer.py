"""
HDF5 í‚¤í¬ì¸íŠ¸ ë°ì´í„°ë¥¼ ì½ê³  ë¶„ì„í•˜ëŠ” ìœ í‹¸ë¦¬í‹°

HDF5 íŒŒì¼ì˜ êµ¬ì¡°ë¥¼ íƒìƒ‰í•˜ê³  ë°ì´í„°ë¥¼ ì‹œê°í™”í•˜ëŠ” ê¸°ëŠ¥ì„ ì œê³µí•©ë‹ˆë‹¤.
"""

import h5py
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from pathlib import Path
import argparse
from tqdm import tqdm
from collections import Counter


def explore_hdf5_structure(file_path):
    """HDF5 íŒŒì¼ì˜ êµ¬ì¡°ë¥¼ íƒìƒ‰í•˜ê³  ì¶œë ¥
    
    Args:
        file_path: HDF5 íŒŒì¼ ê²½ë¡œ
    """
    
    def print_structure(name, obj):
        indent = "  " * name.count('/')
        if isinstance(obj, h5py.Group):
            print(f"{indent}{name}/ (Group)")
            # ì†ì„± ì¶œë ¥
            for attr_name, attr_value in obj.attrs.items():
                print(f"{indent}  @{attr_name}: {attr_value}")
        elif isinstance(obj, h5py.Dataset):
            print(f"{indent}{name} (Dataset): shape={obj.shape}, dtype={obj.dtype}")
            # ì†ì„± ì¶œë ¥
            for attr_name, attr_value in obj.attrs.items():
                print(f"{indent}  @{attr_name}: {attr_value}")
    
    print(f"\n=== HDF5 File Structure: {Path(file_path).name} ===")
    
    with h5py.File(file_path, 'r') as f:
        # íŒŒì¼ ë ˆë²¨ ì†ì„±
        print("File attributes:")
        for attr_name, attr_value in f.attrs.items():
            print(f"  @{attr_name}: {attr_value}")
        
        print("\nFile structure:")
        f.visititems(print_structure)


def load_keypoints_data(file_path, person_id=None):
    """HDF5 íŒŒì¼ì—ì„œ í‚¤í¬ì¸íŠ¸ ë°ì´í„° ë¡œë“œ
    
    Args:
        file_path: HDF5 íŒŒì¼ ê²½ë¡œ
        person_id: íŠ¹ì • ì‚¬ëŒ ID (Noneì´ë©´ ëª¨ë“  ì‚¬ëŒ)
        
    Returns:
        dict: ì‚¬ëŒë³„ í‚¤í¬ì¸íŠ¸ ë°ì´í„°
    """
    
    data = {}
    
    with h5py.File(file_path, 'r') as f:
        # Ground truth ë¡œë“œ (ìˆëŠ” ê²½ìš°)
        ground_truth = None
        if 'ground_truth' in f:
            ground_truth = f['ground_truth'][:]
        
        # ê° ì‚¬ëŒì˜ ë°ì´í„° ë¡œë“œ
        for person_key in f.keys():
            if person_key == 'ground_truth':
                continue
                
            if person_id is not None and person_key != person_id:
                continue
                
            person_group = f[person_key]
            
            person_data = {
                'frame_numbers': person_group['frame_numbers'][:],
                'keypoints': person_group['keypoints'][:],
                'total_frames': person_group.attrs.get('total_frames', 0),
                'num_keypoints': person_group.attrs.get('num_keypoints', 0)
            }
            
            # ìŠ¤ì½”ì–´ ë°ì´í„° (ìˆëŠ” ê²½ìš°)
            if 'scores' in person_group:
                person_data['scores'] = person_group['scores'][:]
            
            data[person_key] = person_data
        
        data['ground_truth'] = ground_truth
    
    return data


def analyze_dataset_statistics(hdf5_dir):
    """ë°ì´í„°ì…‹ì˜ í†µê³„ ì •ë³´ ë¶„ì„
    
    Args:
        hdf5_dir: HDF5 íŒŒì¼ë“¤ì´ ìˆëŠ” ë””ë ‰í† ë¦¬
    """
    
    hdf5_files = list(Path(hdf5_dir).glob("*.h5"))
    
    if not hdf5_files:
        print(f"No HDF5 files found in {hdf5_dir}")
        return
    
    print(f"\n=== Dataset Statistics ===")
    print(f"Total files: {len(hdf5_files)}")
    
    total_persons = 0
    total_frames = 0
    keypoint_counts = []
    frame_counts = []
    files_with_gt = 0
    
    for hdf5_file in tqdm(hdf5_files, desc="Analyzing files"):
        try:
            with h5py.File(hdf5_file, 'r') as f:
                # íŒŒì¼ë³„ í†µê³„
                file_persons = f.attrs.get('total_persons', 0)
                has_gt = f.attrs.get('has_ground_truth', False)
                
                total_persons += file_persons
                if has_gt:
                    files_with_gt += 1
                
                # ê° ì‚¬ëŒë³„ í†µê³„
                for person_key in f.keys():
                    if person_key == 'ground_truth':
                        continue
                    
                    person_group = f[person_key]
                    person_frames = person_group.attrs.get('total_frames', 0)
                    person_keypoints = person_group.attrs.get('num_keypoints', 0)
                    
                    total_frames += person_frames
                    frame_counts.append(person_frames)
                    keypoint_counts.append(person_keypoints)
                    
        except Exception as e:
            print(f"Error analyzing {hdf5_file}: {str(e)}")
    
    print(f"Total persons: {total_persons}")
    print(f"Total frames: {total_frames}")
    print(f"Files with ground truth: {files_with_gt}")
    
    if frame_counts:
        print(f"\nFrame statistics per person:")
        print(f"  Mean: {np.mean(frame_counts):.2f}")
        print(f"  Std: {np.std(frame_counts):.2f}")
        print(f"  Min: {np.min(frame_counts)}")
        print(f"  Max: {np.max(frame_counts)}")
    
    if keypoint_counts:
        unique_keypoints = np.unique(keypoint_counts)
        print(f"\nKeypoint counts: {unique_keypoints}")
        for count in unique_keypoints:
            num_persons = np.sum(np.array(keypoint_counts) == count)
            print(f"  {count} keypoints: {num_persons} persons")


def analyze_ground_truth_labels(hdf5_dir):
    """HDF5 ë°ì´í„°ì…‹ì˜ ground truth ë¼ë²¨ ë¶„ì„
    
    Args:
        hdf5_dir: HDF5 íŒŒì¼ë“¤ì´ ìˆëŠ” ë””ë ‰í† ë¦¬ ê²½ë¡œ
    """
    
    hdf5_dir = Path(hdf5_dir)
    h5_files = list(hdf5_dir.glob("*.h5"))
    
    if not h5_files:
        print(f"No HDF5 files found in {hdf5_dir}")
        return
    
    print(f"\nğŸ·ï¸ Ground Truth ë¼ë²¨ ë¶„ì„ ({hdf5_dir.name})")
    print("=" * 50)
    
    total_normal_frames = 0
    total_abnormal_frames = 0
    normal_files = 0
    abnormal_files = 0
    files_with_gt = 0
    files_without_gt = 0
    
    label_distribution = []
    file_details = []
    
    # ë©”íƒ€ë°ì´í„° íŒŒì¼ ì œì™¸
    h5_files = [f for f in h5_files if f.stem != "video_metadata"]
    
    for h5_file in tqdm(sorted(h5_files), desc="ë¶„ì„ ì¤‘"):
            
        filename = h5_file.stem
        is_abnormal_file = filename.startswith('abnormal_')
        
        try:
            with h5py.File(h5_file, 'r') as f:
                if 'ground_truth' in f:
                    files_with_gt += 1
                    gt_data = f['ground_truth'][:]
                    
                    # ë¼ë²¨ ê°œìˆ˜ ì„¸ê¸°
                    label_counts = Counter(gt_data)
                    zeros = label_counts.get(0, 0)  # ì •ìƒ
                    ones = label_counts.get(1, 0)   # ì´ìƒ
                    
                    total_normal_frames += zeros
                    total_abnormal_frames += ones
                    
                    # íŒŒì¼ ë¶„ë¥˜
                    if is_abnormal_file:
                        abnormal_files += 1
                    else:
                        normal_files += 1
                    
                    # ìƒì„¸ ì •ë³´ ì €ì¥
                    file_details.append({
                        'filename': filename,
                        'is_abnormal': is_abnormal_file,
                        'normal_frames': zeros,
                        'abnormal_frames': ones,
                        'total_frames': len(gt_data)
                    })
                    
                    # ë¼ë²¨ ë¶„í¬ ì €ì¥
                    label_distribution.extend(gt_data)
                    
                else:
                    files_without_gt += 1
                    print(f"âš ï¸  Ground truth ì—†ìŒ: {filename}")
                    
        except Exception as e:
            print(f"âŒ íŒŒì¼ ì²˜ë¦¬ ì˜¤ë¥˜ - {filename}: {str(e)}")
    
    # ê²°ê³¼ ì¶œë ¥
    print(f"\nğŸ“Š íŒŒì¼ í†µê³„:")
    print(f"  ì´ íŒŒì¼ ê°œìˆ˜: {len(h5_files)}ê°œ")
    print(f"  Ground truth ìˆëŠ” íŒŒì¼: {files_with_gt}ê°œ")
    print(f"  Ground truth ì—†ëŠ” íŒŒì¼: {files_without_gt}ê°œ")
    print(f"  ì •ìƒ íŒŒì¼ (normal_*): {normal_files}ê°œ")
    print(f"  ì´ìƒ íŒŒì¼ (abnormal_*): {abnormal_files}ê°œ")
    
    print(f"\nğŸ·ï¸ ë¼ë²¨ í†µê³„:")
    print(f"  ì •ìƒ í”„ë ˆì„ (ë¼ë²¨=0): {total_normal_frames:,}ê°œ")
    print(f"  ì´ìƒ í”„ë ˆì„ (ë¼ë²¨=1): {total_abnormal_frames:,}ê°œ")
    print(f"  ì´ í”„ë ˆì„: {total_normal_frames + total_abnormal_frames:,}ê°œ")
    
    if total_normal_frames + total_abnormal_frames > 0:
        normal_ratio = total_normal_frames / (total_normal_frames + total_abnormal_frames) * 100
        abnormal_ratio = total_abnormal_frames / (total_normal_frames + total_abnormal_frames) * 100
        print(f"  ì •ìƒ:ì´ìƒ ë¹„ìœ¨ = {normal_ratio:.1f}%:{abnormal_ratio:.1f}%")
    
    # íŒŒì¼ë³„ ìƒì„¸ ë¶„ì„
    if file_details:
        print(f"\nğŸ“ˆ íŒŒì¼ë³„ ë¼ë²¨ ë¶„í¬:")
        
        # ì •ìƒ íŒŒì¼ë“¤ì˜ ë¼ë²¨ ë¶„í¬
        normal_file_details = [f for f in file_details if not f['is_abnormal']]
        if normal_file_details:
            normal_0_frames = sum(f['normal_frames'] for f in normal_file_details)
            normal_1_frames = sum(f['abnormal_frames'] for f in normal_file_details)
            print(f"  ì •ìƒ íŒŒì¼ë“¤ ({len(normal_file_details)}ê°œ):")
            print(f"    ë¼ë²¨=0 í”„ë ˆì„: {normal_0_frames:,}ê°œ")
            print(f"    ë¼ë²¨=1 í”„ë ˆì„: {normal_1_frames:,}ê°œ")
        
        # ì´ìƒ íŒŒì¼ë“¤ì˜ ë¼ë²¨ ë¶„í¬
        abnormal_file_details = [f for f in file_details if f['is_abnormal']]
        if abnormal_file_details:
            abnormal_0_frames = sum(f['normal_frames'] for f in abnormal_file_details)
            abnormal_1_frames = sum(f['abnormal_frames'] for f in abnormal_file_details)
            print(f"  ì´ìƒ íŒŒì¼ë“¤ ({len(abnormal_file_details)}ê°œ):")
            print(f"    ë¼ë²¨=0 í”„ë ˆì„: {abnormal_0_frames:,}ê°œ")
            print(f"    ë¼ë²¨=1 í”„ë ˆì„: {abnormal_1_frames:,}ê°œ")
    
    # ë¼ë²¨ ë¶„í¬ íˆìŠ¤í† ê·¸ë¨ (ì„ íƒì )
    if label_distribution and len(set(label_distribution)) > 1:
        unique_labels, counts = np.unique(label_distribution, return_counts=True)
        print(f"\nğŸ“Š ì „ì²´ ë¼ë²¨ ë¶„í¬:")
        for label, count in zip(unique_labels, counts):
            percentage = count / len(label_distribution) * 100
            print(f"  ë¼ë²¨ {label}: {count:,}ê°œ ({percentage:.1f}%)")
    
    return {
        'total_files': len(h5_files),
        'files_with_gt': files_with_gt,
        'normal_files': normal_files,
        'abnormal_files': abnormal_files,
        'normal_frames': total_normal_frames,
        'abnormal_frames': total_abnormal_frames,
        'file_details': file_details
    }


def visualize_keypoints(keypoints, frame_idx=0, title="Keypoints Visualization"):
    """í‚¤í¬ì¸íŠ¸ ì‹œê°í™”
    
    Args:
        keypoints: í‚¤í¬ì¸íŠ¸ ë°ì´í„° (frames, keypoints, 3)
        frame_idx: ì‹œê°í™”í•  í”„ë ˆì„ ì¸ë±ìŠ¤
        title: í”Œë¡¯ ì œëª©
    """
    
    if len(keypoints.shape) != 3 or keypoints.shape[2] != 3:
        print("Invalid keypoints shape. Expected (frames, keypoints, 3)")
        return
    
    if frame_idx >= keypoints.shape[0]:
        print(f"Frame index {frame_idx} out of range. Max: {keypoints.shape[0]-1}")
        return
    
    frame_keypoints = keypoints[frame_idx]
    
    # ìœ íš¨í•œ í‚¤í¬ì¸íŠ¸ë§Œ í•„í„°ë§ (confidence > 0)
    valid_keypoints = frame_keypoints[frame_keypoints[:, 2] > 0]
    
    if len(valid_keypoints) == 0:
        print("No valid keypoints found in this frame")
        return
    
    plt.figure(figsize=(10, 8))
    
    # í‚¤í¬ì¸íŠ¸ ì‹œê°í™”
    x_coords = valid_keypoints[:, 0]
    y_coords = valid_keypoints[:, 1]
    confidences = valid_keypoints[:, 2]
    
    # ìŠ¤ì¼€í„° í”Œë¡¯ - confidenceì— ë”°ë¼ ìƒ‰ìƒê³¼ í¬ê¸° ì¡°ì ˆ
    scatter = plt.scatter(x_coords, y_coords, c=confidences, s=confidences*100, 
                         cmap='viridis', alpha=0.7, edgecolors='black', linewidth=0.5)
    
    # í‚¤í¬ì¸íŠ¸ ë²ˆí˜¸ í‘œì‹œ
    for i, (x, y, conf) in enumerate(valid_keypoints):
        plt.annotate(str(i), (x, y), xytext=(5, 5), textcoords='offset points',
                    fontsize=8, color='red', fontweight='bold')
    
    plt.colorbar(scatter, label='Confidence')
    plt.xlabel('X coordinate')
    plt.ylabel('Y coordinate')
    plt.title(f"{title} - Frame {frame_idx}")
    plt.grid(True, alpha=0.3)
    
    # Yì¶• ë’¤ì§‘ê¸° (ì´ë¯¸ì§€ ì¢Œí‘œê³„)
    plt.gca().invert_yaxis()
    
    plt.tight_layout()
    plt.show()


def plot_keypoint_trajectory(keypoints, keypoint_idx=0, title="Keypoint Trajectory"):
    """íŠ¹ì • í‚¤í¬ì¸íŠ¸ì˜ ì‹œê°„ì— ë”°ë¥¸ ê¶¤ì  ì‹œê°í™”
    
    Args:
        keypoints: í‚¤í¬ì¸íŠ¸ ë°ì´í„° (frames, keypoints, 3)
        keypoint_idx: ì¶”ì í•  í‚¤í¬ì¸íŠ¸ ì¸ë±ìŠ¤
        title: í”Œë¡¯ ì œëª©
    """
    
    if keypoint_idx >= keypoints.shape[1]:
        print(f"Keypoint index {keypoint_idx} out of range. Max: {keypoints.shape[1]-1}")
        return
    
    # íŠ¹ì • í‚¤í¬ì¸íŠ¸ì˜ ê¶¤ì  ì¶”ì¶œ
    trajectory = keypoints[:, keypoint_idx, :]
    
    # ìœ íš¨í•œ í”„ë ˆì„ë§Œ í•„í„°ë§
    valid_frames = trajectory[:, 2] > 0
    valid_trajectory = trajectory[valid_frames]
    
    if len(valid_trajectory) == 0:
        print(f"No valid data found for keypoint {keypoint_idx}")
        return
    
    fig, axes = plt.subplots(2, 2, figsize=(12, 10))
    
    # X ì¢Œí‘œ ë³€í™”
    axes[0, 0].plot(valid_trajectory[:, 0], 'b.-', alpha=0.7)
    axes[0, 0].set_title(f'X coordinate over time - Keypoint {keypoint_idx}')
    axes[0, 0].set_xlabel('Frame')
    axes[0, 0].set_ylabel('X coordinate')
    axes[0, 0].grid(True, alpha=0.3)
    
    # Y ì¢Œí‘œ ë³€í™”
    axes[0, 1].plot(valid_trajectory[:, 1], 'r.-', alpha=0.7)
    axes[0, 1].set_title(f'Y coordinate over time - Keypoint {keypoint_idx}')
    axes[0, 1].set_xlabel('Frame')
    axes[0, 1].set_ylabel('Y coordinate')
    axes[0, 1].grid(True, alpha=0.3)
    
    # Confidence ë³€í™”
    axes[1, 0].plot(valid_trajectory[:, 2], 'g.-', alpha=0.7)
    axes[1, 0].set_title(f'Confidence over time - Keypoint {keypoint_idx}')
    axes[1, 0].set_xlabel('Frame')
    axes[1, 0].set_ylabel('Confidence')
    axes[1, 0].grid(True, alpha=0.3)
    
    # 2D ê¶¤ì 
    axes[1, 1].plot(valid_trajectory[:, 0], valid_trajectory[:, 1], 'purple', alpha=0.7, linewidth=2)
    axes[1, 1].scatter(valid_trajectory[0, 0], valid_trajectory[0, 1], c='green', s=100, marker='o', label='Start')
    axes[1, 1].scatter(valid_trajectory[-1, 0], valid_trajectory[-1, 1], c='red', s=100, marker='x', label='End')
    axes[1, 1].set_title(f'2D Trajectory - Keypoint {keypoint_idx}')
    axes[1, 1].set_xlabel('X coordinate')
    axes[1, 1].set_ylabel('Y coordinate')
    axes[1, 1].legend()
    axes[1, 1].grid(True, alpha=0.3)
    axes[1, 1].invert_yaxis()
    
    plt.suptitle(title)
    plt.tight_layout()
    plt.show()


def main():
    parser = argparse.ArgumentParser(description='Analyze HDF5 keypoint data')
    parser.add_argument('--hdf5_dir', type=str, default='dataset_hdf5',
                      help='Directory containing HDF5 files')
    parser.add_argument('--file', type=str, help='Specific HDF5 file to analyze')
    parser.add_argument('--person_id', type=str, help='Specific person ID to analyze')
    parser.add_argument('--visualize', action='store_true', help='Create visualizations')
    parser.add_argument('--stats_only', action='store_true', help='Only show statistics')
    parser.add_argument('--test_only', action='store_true', help='Analyze only test data ground truth')
    parser.add_argument('--gt_only', action='store_true', help='Analyze only ground truth labels')
    
    args = parser.parse_args()
    
    if args.file:
        # íŠ¹ì • íŒŒì¼ ë¶„ì„
        file_path = Path(args.file)
        if not file_path.exists():
            print(f"File not found: {file_path}")
            return
        
        # íŒŒì¼ êµ¬ì¡° íƒìƒ‰
        explore_hdf5_structure(file_path)
        
        if not args.stats_only:
            # ë°ì´í„° ë¡œë“œ
            data = load_keypoints_data(file_path, args.person_id)
            
            # ë°ì´í„° ì •ë³´ ì¶œë ¥
            print(f"\n=== Data Information ===")
            for person_id, person_data in data.items():
                if person_id == 'ground_truth':
                    continue
                    
                print(f"\nPerson: {person_id}")
                print(f"  Total frames: {person_data['total_frames']}")
                print(f"  Keypoints per frame: {person_data['num_keypoints']}")
                print(f"  Keypoints shape: {person_data['keypoints'].shape}")
                
                if 'scores' in person_data:
                    print(f"  Scores shape: {person_data['scores'].shape}")
            
            if data['ground_truth'] is not None:
                print(f"\nGround Truth: {data['ground_truth'].shape}")
            
            # ì‹œê°í™”
            if args.visualize and not args.stats_only:
                for person_id, person_data in data.items():
                    if person_id == 'ground_truth':
                        continue
                    
                    keypoints = person_data['keypoints']
                    if len(keypoints) > 0:
                        print(f"\nVisualizing data for {person_id}...")
                        
                        # ì²« ë²ˆì§¸ í”„ë ˆì„ í‚¤í¬ì¸íŠ¸ ì‹œê°í™”
                        visualize_keypoints(keypoints, frame_idx=0, 
                                          title=f"{person_id} - Keypoints")
                        
                        # ì²« ë²ˆì§¸ í‚¤í¬ì¸íŠ¸ì˜ ê¶¤ì  ì‹œê°í™”
                        if keypoints.shape[1] > 0:
                            plot_keypoint_trajectory(keypoints, keypoint_idx=0,
                                                   title=f"{person_id} - Keypoint Trajectory")
                        
                        break  # ì²« ë²ˆì§¸ ì‚¬ëŒë§Œ ì‹œê°í™”
    
    else:
        # ì „ì²´ ë°ì´í„°ì…‹ í†µê³„
        hdf5_dir = Path(args.hdf5_dir)
        
        if args.test_only or args.gt_only:
            # í…ŒìŠ¤íŠ¸ ë°ì´í„°ë§Œ ë¶„ì„
            test_dir = hdf5_dir / "test"
            if test_dir.exists():
                print("=== Test Data Ground Truth Analysis ===")
                if args.gt_only:
                    analyze_ground_truth_labels(test_dir)
                else:
                    analyze_dataset_statistics(test_dir)
                    analyze_ground_truth_labels(test_dir)
            else:
                print(f"Test directory not found: {test_dir}")
        else:
            # ì „ì²´ ë°ì´í„°ì…‹ ë¶„ì„
            # Train ë°ì´í„° ë¶„ì„
            train_dir = hdf5_dir / "train"
            if train_dir.exists():
                print("=== Training Data Analysis ===")
                analyze_dataset_statistics(train_dir)
                analyze_ground_truth_labels(train_dir)
            
            # Test ë°ì´í„° ë¶„ì„
            test_dir = hdf5_dir / "test"
            if test_dir.exists():
                print("\n=== Test Data Analysis ===")
                analyze_dataset_statistics(test_dir)
                analyze_ground_truth_labels(test_dir)


if __name__ == "__main__":
    main()