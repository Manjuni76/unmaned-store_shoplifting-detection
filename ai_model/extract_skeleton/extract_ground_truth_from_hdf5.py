"""
HDF5 íŒŒì¼ì—ì„œ Ground Truthë¥¼ ì¶”ì¶œí•˜ì—¬ ë³„ë„ í´ë”ì— ì €ì¥
íŒŒì¼ëª…ì´ ë§¤ì¹˜ë˜ë„ë¡ êµ¬ì„±
"""

import h5py
import numpy as np
from pathlib import Path
from tqdm import tqdm


def extract_ground_truth_from_hdf5():
    """HDF5 íŒŒì¼ì—ì„œ ground truthë¥¼ ì¶”ì¶œí•˜ì—¬ ë³„ë„ í´ë”ì— ì €ì¥"""
    
    print("ğŸ”„ HDF5ì—ì„œ Ground Truth ì¶”ì¶œ ì¤‘...")
    
    # ì…ë ¥/ì¶œë ¥ ë””ë ‰í† ë¦¬
    hdf5_dirs = [
        Path("dataset_hdf5/train"),
        Path("dataset_hdf5/test")
    ]
    
    for hdf5_dir in hdf5_dirs:
        if not hdf5_dir.exists():
            continue
            
        print(f"\nğŸ“ ì²˜ë¦¬ ì¤‘: {hdf5_dir}")
        
        # Ground truth ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±
        gt_output_dir = Path(f"dataset_hdf5_ground_truth/{hdf5_dir.name}")
        gt_output_dir.mkdir(parents=True, exist_ok=True)
        
        # HDF5 íŒŒì¼ë“¤ ì²˜ë¦¬
        h5_files = [f for f in hdf5_dir.glob("*.h5") if f.stem != "video_metadata"]
        
        success_count = 0
        fail_count = 0
        
        for h5_file in tqdm(h5_files, desc=f"{hdf5_dir.name} ì¶”ì¶œ"):
            try:
                filename_base = h5_file.stem  # í™•ì¥ì ì œê±°
                
                with h5py.File(h5_file, 'r') as f:
                    if 'ground_truth' in f:
                        gt_data = f['ground_truth'][:]
                        
                        # Ground truth íŒŒì¼ ì €ì¥
                        gt_filename = f"{filename_base}_gt.npy"
                        gt_filepath = gt_output_dir / gt_filename
                        
                        np.save(gt_filepath, gt_data)
                        
                        success_count += 1
                        
                        # ê°„ë‹¨í•œ ê²€ì¦
                        unique, counts = np.unique(gt_data, return_counts=True)
                        label_dist = dict(zip(unique, counts))
                        
                        print(f"âœ… {filename_base}: {len(gt_data)}í”„ë ˆì„, ë¶„í¬ {label_dist}")
                        
                    else:
                        print(f"âŒ Ground truth ì—†ìŒ: {filename_base}")
                        fail_count += 1
                        
            except Exception as e:
                print(f"âŒ ì²˜ë¦¬ ì˜¤ë¥˜ - {h5_file.name}: {e}")
                fail_count += 1
        
        print(f"\nğŸ“Š {hdf5_dir.name} ê²°ê³¼:")
        print(f"  ì„±ê³µ: {success_count}ê°œ")
        print(f"  ì‹¤íŒ¨: {fail_count}ê°œ")
        print(f"  ì €ì¥ ìœ„ì¹˜: {gt_output_dir}")


def verify_extracted_ground_truth():
    """ì¶”ì¶œëœ ground truth íŒŒì¼ë“¤ ê²€ì¦"""
    
    print("\nğŸ” ì¶”ì¶œëœ Ground Truth íŒŒì¼ ê²€ì¦...")
    
    gt_dirs = [
        Path("dataset_hdf5_ground_truth/train"),
        Path("dataset_hdf5_ground_truth/test")
    ]
    
    for gt_dir in gt_dirs:
        if not gt_dir.exists():
            continue
            
        print(f"\nğŸ“ ê²€ì¦ ì¤‘: {gt_dir}")
        
        gt_files = list(gt_dir.glob("*_gt.npy"))
        
        total_normal_frames = 0
        total_abnormal_frames = 0
        normal_files = 0
        abnormal_files = 0
        
        for gt_file in sorted(gt_files):
            filename_base = gt_file.stem.replace('_gt', '')
            is_abnormal = filename_base.startswith('abnormal_')
            
            try:
                gt_data = np.load(gt_file)
                unique, counts = np.unique(gt_data, return_counts=True)
                label_counts = dict(zip(unique, counts))
                
                zeros = label_counts.get(0, 0)
                ones = label_counts.get(1, 0)
                
                total_normal_frames += zeros
                total_abnormal_frames += ones
                
                if is_abnormal:
                    abnormal_files += 1
                else:
                    normal_files += 1
                    
            except Exception as e:
                print(f"âŒ ê²€ì¦ ì˜¤ë¥˜ - {gt_file.name}: {e}")
        
        print(f"  ì´ íŒŒì¼: {len(gt_files)}ê°œ")
        print(f"  ì •ìƒ íŒŒì¼: {normal_files}ê°œ")
        print(f"  ì´ìƒ íŒŒì¼: {abnormal_files}ê°œ")
        print(f"  ì •ìƒ í”„ë ˆì„ (ë¼ë²¨=0): {total_normal_frames:,}ê°œ")
        print(f"  ì´ìƒ í”„ë ˆì„ (ë¼ë²¨=1): {total_abnormal_frames:,}ê°œ")
        
        if total_normal_frames + total_abnormal_frames > 0:
            normal_ratio = total_normal_frames / (total_normal_frames + total_abnormal_frames) * 100
            abnormal_ratio = total_abnormal_frames / (total_normal_frames + total_abnormal_frames) * 100
            print(f"  ì •ìƒ:ì´ìƒ ë¹„ìœ¨ = {normal_ratio:.1f}%:{abnormal_ratio:.1f}%")


def compare_with_original_npy():
    """ì›ë³¸ NPY íŒŒì¼ê³¼ ë¹„êµ"""
    
    print("\nğŸ”„ ì›ë³¸ NPYì™€ ì¶”ì¶œëœ Ground Truth ë¹„êµ...")
    
    # í…ŒìŠ¤íŠ¸ ë°ì´í„°ë§Œ ë¹„êµ (ì›ë³¸ NPYê°€ ìˆëŠ” ê²½ìš°)
    original_npy_dir = Path("dataset_output/test/ground_truth")
    extracted_gt_dir = Path("dataset_hdf5_ground_truth/test")
    
    if not original_npy_dir.exists() or not extracted_gt_dir.exists():
        print("ë¹„êµí•  ë””ë ‰í† ë¦¬ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    original_files = list(original_npy_dir.glob("*_gt.npy"))
    extracted_files = list(extracted_gt_dir.glob("*_gt.npy"))
    
    print(f"ì›ë³¸ NPY: {len(original_files)}ê°œ")
    print(f"ì¶”ì¶œëœ GT: {len(extracted_files)}ê°œ")
    
    # íŒŒì¼ëª… ë§¤ì¹­í•´ì„œ ë¹„êµ
    match_count = 0
    mismatch_count = 0
    
    for orig_file in original_files:
        extracted_file = extracted_gt_dir / orig_file.name
        
        if extracted_file.exists():
            try:
                orig_data = np.load(orig_file)
                extracted_data = np.load(extracted_file)
                
                if np.array_equal(orig_data, extracted_data):
                    match_count += 1
                else:
                    mismatch_count += 1
                    print(f"âŒ ë¶ˆì¼ì¹˜: {orig_file.name}")
                    print(f"  ì›ë³¸: {len(orig_data)}í”„ë ˆì„, ì¶”ì¶œ: {len(extracted_data)}í”„ë ˆì„")
                    
            except Exception as e:
                print(f"âŒ ë¹„êµ ì˜¤ë¥˜ - {orig_file.name}: {e}")
                mismatch_count += 1
        else:
            print(f"âŒ ì¶”ì¶œëœ íŒŒì¼ ì—†ìŒ: {orig_file.name}")
            mismatch_count += 1
    
    print(f"\nğŸ“Š ë¹„êµ ê²°ê³¼:")
    print(f"  ì¼ì¹˜: {match_count}ê°œ")
    print(f"  ë¶ˆì¼ì¹˜: {mismatch_count}ê°œ")
    
    if match_count > 0 and mismatch_count == 0:
        print("âœ… ëª¨ë“  íŒŒì¼ì´ ì™„ë²½í•˜ê²Œ ì¼ì¹˜í•©ë‹ˆë‹¤!")
    elif match_count > 0:
        print("âš ï¸ ì¼ë¶€ íŒŒì¼ì— ì°¨ì´ê°€ ìˆìŠµë‹ˆë‹¤.")
    else:
        print("âŒ ëª¨ë“  íŒŒì¼ì´ ë¶ˆì¼ì¹˜í•©ë‹ˆë‹¤.")


def main():
    print("ğŸš€ HDF5ì—ì„œ Ground Truth ì¶”ì¶œ ì‘ì—… ì‹œì‘")
    print("=" * 60)
    
    # 1. Ground Truth ì¶”ì¶œ
    extract_ground_truth_from_hdf5()
    
    # 2. ì¶”ì¶œëœ íŒŒì¼ ê²€ì¦
    verify_extracted_ground_truth()
    
    # 3. ì›ë³¸ê³¼ ë¹„êµ (ìˆëŠ” ê²½ìš°)
    compare_with_original_npy()
    
    print("\nğŸ‰ Ground Truth ì¶”ì¶œ ì™„ë£Œ!")
    print("ğŸ“ ì €ì¥ ìœ„ì¹˜:")
    print("  - dataset_hdf5_ground_truth/train/")
    print("  - dataset_hdf5_ground_truth/test/")
    print("\nğŸ’¡ íŒŒì¼ëª… í˜•ì‹: [ì›ë³¸íŒŒì¼ëª…]_gt.npy")


if __name__ == "__main__":
    main()