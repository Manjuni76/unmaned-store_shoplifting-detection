import subprocess
import sys
import time
import re
import matplotlib.pyplot as plt
import pandas as pd
import os
import numpy as np
from datetime import datetime

# matplotlib í•œê¸€ í°íŠ¸ ì„¤ì •
plt.rcParams['font.family'] = ['DejaVu Sans', 'Arial', 'sans-serif']
plt.rcParams['axes.unicode_minus'] = False

def run_experiment(subset_name, seed=42):
    """íŠ¹ì • ê´€ì ˆ ë¶€ìœ„ì™€ ì‹œë“œë¡œ ì‹¤í—˜ ì‹¤í–‰"""
    print(f"ğŸš€ Running {subset_name} (seed: {seed})...", end=" ", flush=True)
    
    # ê´€ì ˆ ë¶€ìœ„ì— ë”°ë¼ ë°°ì¹˜ í¬ê¸° ìµœì í™”
    batch_size = 256
    epochs = 50
    
    try:
        # subprocessë¡œ train_eval.py ì‹¤í–‰í•˜ê³  ì…ë ¥ ìë™í™”
        process = subprocess.Popen(
            [sys.executable, 'train_eval.py', 
             '--batch_size', str(batch_size), 
             '--epochs', str(epochs)],
            stdin=subprocess.PIPE,
            stdout=subprocess.PIPE,
            stderr=subprocess.STDOUT,  # stderrì„ stdoutìœ¼ë¡œ ë¦¬ë””ë ‰ì…˜
            text=True,
            universal_newlines=True
        )
        
        # ê´€ì ˆ ë¶€ìœ„ì™€ ì‹œë“œ ì„ íƒ ì…ë ¥ (ì—¬ëŸ¬ ì¤„ ì…ë ¥)
        inputs = f"{subset_name}\n{seed}\n"
        process.stdin.write(inputs)
        process.stdin.close()
        
        print(f"\nâ³ í•™ìŠµ ì§„í–‰ ì¤‘ (ë°°ì¹˜ í¬ê¸°: {batch_size}, ì—í¬í¬: {epochs})...")
        
        # ì‹¤ì‹œê°„ ì¶œë ¥ ìº¡ì²˜
        output_lines = []
        while True:
            line = process.stdout.readline()
            if not line and process.poll() is not None:
                break
            if line:
                print(line.rstrip())  # ì‹¤ì‹œê°„ ì¶œë ¥
                output_lines.append(line)
        
        stdout = ''.join(output_lines)
        stderr = ""  # stderrì€ ì´ë¯¸ stdoutì— í¬í•¨ë¨
        
        # ê²°ê³¼ë§Œ ì¶”ì¶œ
        results = extract_results(stdout, stderr)  # stderrë„ ì „ë‹¬
        
        if process.returncode == 0 and results:
            print("âœ…")
            return True, results
        else:
            print("âŒ")
            if stderr:
                print(f"Error: {stderr[-200:]}")  # ë§ˆì§€ë§‰ 200ìë§Œ í‘œì‹œ
            return False, None
            
    except subprocess.TimeoutExpired:
        print("â° Timeout")
        process.kill()
        return False, None
    except Exception as e:
        print(f"âŒ Error: {e}")
        return False, None

def extract_results(output, stderr_output=""):
    """ì¶œë ¥ì—ì„œ ê²°ê³¼ê°’ê³¼ í•™ìŠµ ê³¡ì„  ë°ì´í„° ì¶”ì¶œ"""
    results = {}
    
    try:
        # AUC(ROC) ì¶”ì¶œ
        auc_roc_match = re.search(r'auc\(roc\):\s*([\d.]+)', output)
        if auc_roc_match:
            results['auc_roc'] = float(auc_roc_match.group(1))
        
        # AUC(PR) ì¶”ì¶œ  
        auc_pr_match = re.search(r'auc\(pr\):\s*([\d.]+)', output)
        if auc_pr_match:
            results['auc_pr'] = float(auc_pr_match.group(1))
        
        # EER ì¶”ì¶œ
        eer_match = re.search(r'eer:\s*([\d.]+)', output)
        if eer_match:
            results['eer'] = float(eer_match.group(1))
        
        # EER threshold ì¶”ì¶œ
        eer_threshold_match = re.search(r'eer threshold:\s*([\d.-]+)', output)
        if eer_threshold_match:
            results['eer_threshold'] = float(eer_threshold_match.group(1))
        
        # ìƒ˜í”Œ ìˆ˜ ì¶”ì¶œ
        samples_match = re.search(r'Number of samples\s*(\d+)', output)
        if samples_match:
            results['num_samples'] = int(samples_match.group(1))
        
        # Learning rate ë°ì´í„° ì¶”ì¶œ (stdout + stderr ë‘˜ ë‹¤ í™•ì¸)
        learning_data = extract_learning_curves(output, stderr_output)
        if learning_data:
            results['learning_curves'] = learning_data
            
        return results if results else None
        
    except Exception as e:
        print(f"ê²°ê³¼ ì¶”ì¶œ ì˜¤ë¥˜: {e}")
        return None

def extract_learning_curves(stdout_output, stderr_output=""):
    """í•™ìŠµ ê³¡ì„  ë°ì´í„° ì¶”ì¶œ (loss, learning rate ë“±)"""
    learning_data = {
        'epochs': [],
        'train_loss': [],
        'val_loss': [],
        'learning_rates': []
    }
    
    try:
        # Learning rate ì¶”ì¶œ (stdoutì—ì„œ)
        lr_patterns = [
            r'New LR:\s*([\d.e-]+)',
            r'lr:\s*([\d.e-]+)',
            r'learning_rate:\s*([\d.e-]+)',
            r'LR:\s*([\d.e-]+)'
        ]
        
        for pattern in lr_patterns:
            matches = re.findall(pattern, stdout_output)
            if matches:
                learning_data['learning_rates'] = [float(lr) for lr in matches]
                break
        
        # Loss ê°’ë“¤ì„ stderrì—ì„œ ì¶”ì¶œ (ì§„í–‰ë¥  ë°”ì™€ í•¨ê»˜ ì¶œë ¥ë¨)
        if stderr_output:
            # ê° ì—í¬í¬ì˜ ë§ˆì§€ë§‰ Loss ê°’ì„ ì¶”ì¶œ (ì—í¬í¬ ëì— ë‚˜ì˜¤ëŠ” ê°’)
            loss_pattern = r'Loss:\s*([\d.]+):\s*100%.*?(\d+)/(\d+)'
            epoch_loss_matches = re.findall(loss_pattern, stderr_output)
            
            if epoch_loss_matches:
                epoch = 1
                for loss_str, current, total in epoch_loss_matches:
                    learning_data['epochs'].append(epoch)
                    learning_data['train_loss'].append(float(loss_str))
                    epoch += 1
            else:
                # ë°±ì—…: ëª¨ë“  Loss ê°’ ì¤‘ì—ì„œ ëŒ€í‘œê°’ë“¤ì„ ì¶”ì¶œ
                all_loss_matches = re.findall(r'Loss:\s*([\d.]+)', stderr_output)
                if all_loss_matches:
                    # ì—í¬í¬ë³„ë¡œ ë‚˜ëˆ„ì–´ì„œ ê° ì—í¬í¬ì˜ ë§ˆì§€ë§‰ loss ì¶”ì¶œ
                    # stderr ì¶œë ¥ì„ ì—í¬í¬ë³„ë¡œ ë¶„í• 
                    epoch_sections = re.split(r'(\d+)%\|#+\|\s*\d+/\d+.*?\[.*?\]', stderr_output)
                    
                    # ê° ì„¹ì…˜ì—ì„œ ë§ˆì§€ë§‰ Loss ê°’ ì¶”ì¶œ (ê°„ë‹¨í•œ ë°©ë²•)
                    loss_values = []
                    prev_loss = None
                    for loss_str in all_loss_matches:
                        current_loss = float(loss_str)
                        if prev_loss is None or abs(current_loss - prev_loss) > 0.1:
                            # ì˜ë¯¸ìˆëŠ” ë³€í™”ê°€ ìˆì„ ë•Œë§Œ ì¶”ê°€
                            if len(loss_values) < 10:  # ìµœëŒ€ 10ê°œ ì—í¬í¬ê¹Œì§€ë§Œ
                                loss_values.append(current_loss)
                                prev_loss = current_loss
                    
                    # ì—í¬í¬ë³„ë¡œ ëŒ€ëµì ì¸ ëŒ€í‘œê°’ë“¤ ì„ íƒ
                    if len(loss_values) >= 3:
                        step = len(loss_values) // 3
                        selected_losses = [loss_values[0], loss_values[step], loss_values[-1]]
                        
                        for i, loss in enumerate(selected_losses):
                            learning_data['epochs'].append(i + 1)
                            learning_data['train_loss'].append(loss)
        
        print(f"[DEBUG] ì¶”ì¶œëœ í•™ìŠµ ë°ì´í„°: epochs={len(learning_data['epochs'])}, train_loss={len(learning_data['train_loss'])}, lr={len(learning_data['learning_rates'])}")
        if learning_data['train_loss']:
            print(f"[DEBUG] Loss ê°’ë“¤: {learning_data['train_loss']}")
        
        # ë°ì´í„°ê°€ ìˆìœ¼ë©´ ë°˜í™˜, ì—†ìœ¼ë©´ None ë°˜í™˜
        if learning_data['epochs'] or learning_data['learning_rates']:
            return learning_data
        
        return None
        
    except Exception as e:
        print(f"í•™ìŠµ ê³¡ì„  ë°ì´í„° ì¶”ì¶œ ì˜¤ë¥˜: {e}")
        return None

def save_learning_curves_plot(all_results, time_str):
    """í•™ìŠµ ê³¡ì„  ê·¸ë˜í”„ë¥¼ PNG íŒŒì¼ë¡œ ì €ì¥"""
    try:
        # ê²°ê³¼ ë””ë ‰í† ë¦¬ í™•ì¸
        plots_dir = os.path.join("results", "plots")
        os.makedirs(plots_dir, exist_ok=True)
        
        # ê° ê´€ì ˆ ë¶€ìœ„ë³„ë¡œ ê·¸ë˜í”„ ìƒì„±
        for subset, seed_results in all_results.items():
            if not seed_results:
                continue
                
            # í•´ë‹¹ ë¶€ìœ„ì— í•™ìŠµ ê³¡ì„  ë°ì´í„°ê°€ ìˆëŠ”ì§€ í™•ì¸
            learning_curves_data = []
            for seed, results in seed_results.items():
                if results and 'learning_curves' in results:
                    learning_curves_data.append((seed, results['learning_curves']))
            
            if not learning_curves_data:
                print(f"ğŸ“Š {subset} ë¶€ìœ„ì— í•™ìŠµ ê³¡ì„  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                continue
            
            # ê·¸ë˜í”„ ìƒì„±
            fig, axes = plt.subplots(2, 2, figsize=(15, 12))
            fig.suptitle(f'Learning Curves - {subset.upper()}', fontsize=16)
            
            # ê° ì‹œë“œë³„ ë°ì´í„° í”Œë¡¯
            colors = plt.cm.tab10(np.linspace(0, 1, len(learning_curves_data)))
            
            has_train_loss = False
            has_val_loss = False
            has_learning_rate = False
            
            for i, (seed, learning_data) in enumerate(learning_curves_data):
                color = colors[i]
                label = f'Seed {seed}'
                
                # Training Loss
                if learning_data['epochs'] and learning_data['train_loss']:
                    axes[0, 0].plot(learning_data['epochs'], learning_data['train_loss'], 
                                   color=color, label=label, marker='o', markersize=4, linewidth=2)
                    has_train_loss = True
                
                # Validation Loss (ìˆëŠ” ê²½ìš°)
                if learning_data['epochs'] and learning_data['val_loss']:
                    axes[0, 1].plot(learning_data['epochs'], learning_data['val_loss'], 
                                   color=color, label=label, marker='s', markersize=4, linewidth=2)
                    has_val_loss = True
                
                # Learning Rate
                if learning_data['learning_rates']:
                    epochs_lr = list(range(1, len(learning_data['learning_rates']) + 1))
                    
                    # ì‹œë“œë³„ë¡œ ë‹¤ë¥¸ ìŠ¤íƒ€ì¼ ì ìš© (ê°™ì€ ê°’ì´ì–´ë„ êµ¬ë¶„ ê°€ëŠ¥í•˜ë„ë¡)
                    linestyles = ['-', '--', '-.', ':', '-']
                    markers = ['o', 's', '^', 'D', 'v']
                    linestyle = linestyles[i % len(linestyles)]
                    marker = markers[i % len(markers)]
                    
                    axes[1, 0].plot(epochs_lr, learning_data['learning_rates'], 
                                   color=color, label=label, linestyle=linestyle,
                                   marker=marker, markersize=6, linewidth=2, alpha=0.8)
                    axes[1, 0].set_yscale('log')
                    has_learning_rate = True
                
                # Combined Loss Comparison
                if learning_data['epochs'] and learning_data['train_loss']:
                    axes[1, 1].plot(learning_data['epochs'], learning_data['train_loss'], 
                                   color=color, label=f'{label} (Train)', linestyle='-', marker='o', markersize=3, linewidth=2)
                if learning_data['epochs'] and learning_data['val_loss']:
                    axes[1, 1].plot(learning_data['epochs'], learning_data['val_loss'], 
                                   color=color, label=f'{label} (Val)', linestyle='--', marker='s', markersize=3, linewidth=1.5)
            
            # ì¶• ì„¤ì •
            axes[0, 0].set_title('Training Loss by Epoch')
            axes[0, 0].set_xlabel('Epoch')
            axes[0, 0].set_ylabel('Loss')
            if has_train_loss:
                axes[0, 0].legend()
            axes[0, 0].grid(True, alpha=0.3)
            
            axes[0, 1].set_title('Validation Loss by Epoch')
            axes[0, 1].set_xlabel('Epoch')
            axes[0, 1].set_ylabel('Loss')
            if has_val_loss:
                axes[0, 1].legend()
            else:
                axes[0, 1].text(0.5, 0.5, 'No Validation Loss Data', 
                               ha='center', va='center', transform=axes[0, 1].transAxes, 
                               fontsize=12, alpha=0.7)
            axes[0, 1].grid(True, alpha=0.3)
            
            axes[1, 0].set_title('Learning Rate Schedule')
            axes[1, 0].set_xlabel('Epoch')
            axes[1, 0].set_ylabel('Learning Rate (log scale)')
            if has_learning_rate:
                axes[1, 0].legend()
            else:
                axes[1, 0].text(0.5, 0.5, 'No Learning Rate Data', 
                               ha='center', va='center', transform=axes[1, 0].transAxes, 
                               fontsize=12, alpha=0.7)
            axes[1, 0].grid(True, alpha=0.3)
            
            axes[1, 1].set_title('Training Loss Comparison')
            axes[1, 1].set_xlabel('Epoch')
            axes[1, 1].set_ylabel('Loss')
            if has_train_loss or has_val_loss:
                axes[1, 1].legend()
            axes[1, 1].grid(True, alpha=0.3)
            
            plt.tight_layout()
            
            # íŒŒì¼ë¡œ ì €ì¥
            plot_path = os.path.join(plots_dir, f"learning_curves_{subset}_{time_str}.png")
            plt.savefig(plot_path, dpi=300, bbox_inches='tight')
            plt.close()
            
            print(f"ğŸ“ˆ í•™ìŠµ ê³¡ì„  ê·¸ë˜í”„ ì €ì¥ë¨: {plot_path}")
        
        return True
        
    except Exception as e:
        print(f"âš ï¸ í•™ìŠµ ê³¡ì„  ê·¸ë˜í”„ ì €ì¥ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return False

def save_performance_comparison_plot(all_results, mode, time_str):
    """ì„±ëŠ¥ ë¹„êµ ê·¸ë˜í”„ë¥¼ PNG íŒŒì¼ë¡œ ì €ì¥"""
    try:
        # ê²°ê³¼ ë””ë ‰í† ë¦¬ í™•ì¸
        plots_dir = os.path.join("results", "plots")
        os.makedirs(plots_dir, exist_ok=True)
        
        # ì„±ëŠ¥ ë°ì´í„° ìˆ˜ì§‘
        performance_data = {subset: {} for subset in all_results.keys()}
        
        for subset, seed_results in all_results.items():
            auc_roc_values = []
            auc_pr_values = []
            eer_values = []
            
            for seed, results in seed_results.items():
                if results:
                    if 'auc_roc' in results:
                        auc_roc_values.append(results['auc_roc'])
                    if 'auc_pr' in results:
                        auc_pr_values.append(results['auc_pr'])
                    if 'eer' in results:
                        eer_values.append(results['eer'])
            
            if auc_roc_values:
                performance_data[subset]['auc_roc_mean'] = np.mean(auc_roc_values)
                performance_data[subset]['auc_roc_std'] = np.std(auc_roc_values)
            if auc_pr_values:
                performance_data[subset]['auc_pr_mean'] = np.mean(auc_pr_values)
                performance_data[subset]['auc_pr_std'] = np.std(auc_pr_values)
            if eer_values:
                performance_data[subset]['eer_mean'] = np.mean(eer_values)
                performance_data[subset]['eer_std'] = np.std(eer_values)
        
        # ìœ íš¨í•œ ë°ì´í„°ê°€ ìˆëŠ” ë¶€ìœ„ë§Œ í•„í„°ë§
        valid_subsets = [subset for subset, data in performance_data.items() 
                        if data and any('mean' in key for key in data.keys())]
        
        if not valid_subsets:
            print("ğŸ“Š ì„±ëŠ¥ ë¹„êµ ê·¸ë˜í”„ë¥¼ ìƒì„±í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return False
        
        # ê·¸ë˜í”„ ìƒì„±
        fig, axes = plt.subplots(2, 2, figsize=(16, 12))
        fig.suptitle('Performance Comparison Across Joint Subsets', fontsize=16)
        
        x_pos = np.arange(len(valid_subsets))
        width = 0.35
        
        # AUC(ROC) ë¹„êµ
        auc_roc_means = [performance_data[subset].get('auc_roc_mean', 0) for subset in valid_subsets]
        auc_roc_stds = [performance_data[subset].get('auc_roc_std', 0) for subset in valid_subsets]
        
        if any(auc_roc_means):
            bars1 = axes[0, 0].bar(x_pos, auc_roc_means, width, yerr=auc_roc_stds, 
                                  capsize=5, alpha=0.8, color='skyblue', edgecolor='navy')
            axes[0, 0].set_title('AUC(ROC) Comparison')
            axes[0, 0].set_ylabel('AUC(ROC)')
            axes[0, 0].set_xticks(x_pos)
            axes[0, 0].set_xticklabels(valid_subsets, rotation=45, ha='right')
            axes[0, 0].grid(True, alpha=0.3)
            
            # ê°’ í‘œì‹œ
            for i, (mean, std) in enumerate(zip(auc_roc_means, auc_roc_stds)):
                if mean > 0:
                    axes[0, 0].text(i, mean + std + 0.01, f'{mean:.3f}Â±{std:.3f}', 
                                   ha='center', va='bottom', fontsize=8)
        
        # AUC(PR) ë¹„êµ
        auc_pr_means = [performance_data[subset].get('auc_pr_mean', 0) for subset in valid_subsets]
        auc_pr_stds = [performance_data[subset].get('auc_pr_std', 0) for subset in valid_subsets]
        
        if any(auc_pr_means):
            bars2 = axes[0, 1].bar(x_pos, auc_pr_means, width, yerr=auc_pr_stds, 
                                  capsize=5, alpha=0.8, color='lightcoral', edgecolor='darkred')
            axes[0, 1].set_title('AUC(PR) Comparison')
            axes[0, 1].set_ylabel('AUC(PR)')
            axes[0, 1].set_xticks(x_pos)
            axes[0, 1].set_xticklabels(valid_subsets, rotation=45, ha='right')
            axes[0, 1].grid(True, alpha=0.3)
            
            # ê°’ í‘œì‹œ
            for i, (mean, std) in enumerate(zip(auc_pr_means, auc_pr_stds)):
                if mean > 0:
                    axes[0, 1].text(i, mean + std + 0.01, f'{mean:.3f}Â±{std:.3f}', 
                                   ha='center', va='bottom', fontsize=8)
        
        # EER ë¹„êµ (ë‚®ì„ìˆ˜ë¡ ì¢‹ìŒ)
        eer_means = [performance_data[subset].get('eer_mean', 0) for subset in valid_subsets]
        eer_stds = [performance_data[subset].get('eer_std', 0) for subset in valid_subsets]
        
        if any(eer_means):
            bars3 = axes[1, 0].bar(x_pos, eer_means, width, yerr=eer_stds, 
                                  capsize=5, alpha=0.8, color='lightgreen', edgecolor='darkgreen')
            axes[1, 0].set_title('EER Comparison (Lower is Better)')
            axes[1, 0].set_ylabel('EER')
            axes[1, 0].set_xticks(x_pos)
            axes[1, 0].set_xticklabels(valid_subsets, rotation=45, ha='right')
            axes[1, 0].grid(True, alpha=0.3)
            
            # ê°’ í‘œì‹œ
            for i, (mean, std) in enumerate(zip(eer_means, eer_stds)):
                if mean > 0:
                    axes[1, 0].text(i, mean + std + 0.01, f'{mean:.3f}Â±{std:.3f}', 
                                   ha='center', va='bottom', fontsize=8)
        
        # ì „ì²´ ì„±ëŠ¥ ì¢…í•© ë¹„êµ (radar chart ìŠ¤íƒ€ì¼ì˜ ì„  ê·¸ë˜í”„)
        if any(auc_roc_means) and any(auc_pr_means):
            ax_combined = axes[1, 1]
            x_labels = [subset[:8] for subset in valid_subsets]  # ë¼ë²¨ ì¶•ì•½
            
            # ì •ê·œí™” (0-1 ìŠ¤ì¼€ì¼)
            if max(auc_roc_means) > 0:
                norm_auc_roc = [x/max(auc_roc_means) for x in auc_roc_means]
                ax_combined.plot(x_labels, norm_auc_roc, 'o-', label='AUC(ROC)', linewidth=2, markersize=6)
            
            if max(auc_pr_means) > 0:
                norm_auc_pr = [x/max(auc_pr_means) for x in auc_pr_means]
                ax_combined.plot(x_labels, norm_auc_pr, 's-', label='AUC(PR)', linewidth=2, markersize=6)
            
            if max(eer_means) > 0:
                # EERì€ ë‚®ì„ìˆ˜ë¡ ì¢‹ìœ¼ë¯€ë¡œ ë°˜ì „
                norm_eer = [(max(eer_means) - x)/max(eer_means) for x in eer_means]
                ax_combined.plot(x_labels, norm_eer, '^-', label='1-EER (normalized)', linewidth=2, markersize=6)
            
            ax_combined.set_title('Normalized Performance Comparison')
            ax_combined.set_ylabel('Normalized Score')
            ax_combined.set_ylim(0, 1.1)
            ax_combined.legend()
            ax_combined.grid(True, alpha=0.3)
            plt.setp(ax_combined.get_xticklabels(), rotation=45, ha='right')
        
        plt.tight_layout()
        
        # íŒŒì¼ë¡œ ì €ì¥
        plot_path = os.path.join(plots_dir, f"performance_comparison_{time_str}.png")
        plt.savefig(plot_path, dpi=300, bbox_inches='tight')
        plt.close()
        
        print(f"ğŸ“Š ì„±ëŠ¥ ë¹„êµ ê·¸ë˜í”„ ì €ì¥ë¨: {plot_path}")
        return True
        
    except Exception as e:
        print(f"âš ï¸ ì„±ëŠ¥ ë¹„êµ ê·¸ë˜í”„ ì €ì¥ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return False

def save_learning_rate_convergence_plot(all_results, time_str):
    """Learning Rate ìˆ˜ë ´ íŒ¨í„´ì„ ë³´ì—¬ì£¼ëŠ” ì „ìš© ê·¸ë˜í”„ë¥¼ PNG íŒŒì¼ë¡œ ì €ì¥"""
    try:
        # ê²°ê³¼ ë””ë ‰í† ë¦¬ í™•ì¸
        plots_dir = os.path.join("results", "plots")
        os.makedirs(plots_dir, exist_ok=True)
        
        # Learning rate ë°ì´í„° ìˆ˜ì§‘
        lr_data_collection = {}
        
        for subset, seed_results in all_results.items():
            if not seed_results:
                continue
                
            lr_data_collection[subset] = []
            for seed, results in seed_results.items():
                if results and 'learning_curves' in results:
                    learning_data = results['learning_curves']
                    if learning_data['learning_rates']:
                        lr_data_collection[subset].append({
                            'seed': seed,
                            'learning_rates': learning_data['learning_rates'],
                            'epochs': list(range(1, len(learning_data['learning_rates']) + 1))
                        })
        
        # ìœ íš¨í•œ ë°ì´í„°ê°€ ìˆëŠ”ì§€ í™•ì¸
        valid_subsets = [subset for subset, data in lr_data_collection.items() if data]
        
        if not valid_subsets:
            print("ğŸ“Š Learning Rate ìˆ˜ë ´ ê·¸ë˜í”„ë¥¼ ìƒì„±í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return False
        
        # ê° ë¶€ìœ„ë³„ë¡œ ë³„ë„ ê·¸ë˜í”„ ìƒì„± (ê°„ë‹¨í•œ ë°©ì‹)
        for subset in valid_subsets:
            lr_data_list = lr_data_collection[subset]
            
            fig, ax = plt.subplots(1, 1, figsize=(10, 6))
            fig.suptitle(f'Learning Rate Convergence - {subset.upper()}', fontsize=14)
            
            # ìƒ‰ìƒ íŒ”ë ˆíŠ¸
            colors = plt.cm.Set1(np.linspace(0, 1, len(lr_data_list)))
            
            for i, lr_info in enumerate(lr_data_list):
                seed = lr_info['seed']
                epochs = lr_info['epochs']
                learning_rates = lr_info['learning_rates']
                color = colors[i]
                
                # ì‹œë“œë³„ë¡œ ë‹¤ë¥¸ ìŠ¤íƒ€ì¼ ì ìš©
                linestyles = ['-', '--', '-.', ':', '-']
                markers = ['o', 's', '^', 'D', 'v']
                linestyle = linestyles[i % len(linestyles)]
                marker = markers[i % len(markers)]
                
                # Learning rate ê³¡ì„  ê·¸ë¦¬ê¸° (ìŠ¤íƒ€ì¼ ì°¨ë³„í™”)
                ax.plot(epochs, learning_rates, linestyle=linestyle, color=color, 
                       label=f'Seed {seed}', linewidth=2.5, marker=marker, 
                       markersize=6, alpha=0.8)
                
                # ìˆ˜ë ´ ê°’ í‘œì‹œ (ë§ˆì§€ë§‰ ê°’)
                final_lr = learning_rates[-1]
                ax.annotate(f'{final_lr:.2e}', 
                           xy=(epochs[-1], final_lr), 
                           xytext=(5, 5), 
                           textcoords='offset points',
                           fontsize=9, color=color, alpha=0.8)
            
            ax.set_title(f'{subset.upper()} - Learning Rate Schedule')
            ax.set_xlabel('Epoch')
            ax.set_ylabel('Learning Rate')
            ax.set_yscale('log')
            ax.legend(loc='best')
            ax.grid(True, alpha=0.3)
            
            plt.tight_layout()
            
            # íŒŒì¼ë¡œ ì €ì¥
            plot_path = os.path.join(plots_dir, f"learning_rate_{subset}_{time_str}.png")
            plt.savefig(plot_path, dpi=300, bbox_inches='tight')
            plt.close()
            
            print(f"ğŸ“ˆ Learning Rate ê·¸ë˜í”„ ì €ì¥ë¨: {plot_path}")
        
        # ëª¨ë“  ë¶€ìœ„ í†µí•© ë¹„êµ ê·¸ë˜í”„
        if len(valid_subsets) > 1:
            fig, ax = plt.subplots(1, 1, figsize=(12, 8))
            fig.suptitle('Learning Rate Convergence - All Joint Subsets Comparison', fontsize=14)
            
            subset_colors = plt.cm.tab10(np.linspace(0, 1, len(valid_subsets)))
            
            for subset_idx, subset in enumerate(valid_subsets):
                lr_data_list = lr_data_collection[subset]
                base_color = subset_colors[subset_idx]
                
                # ê° ì‹œë“œë³„ë¡œ ì•½ê°„ ë‹¤ë¥¸ ìƒ‰ì¡° ì‚¬ìš©
                for seed_idx, lr_info in enumerate(lr_data_list):
                    seed = lr_info['seed']
                    epochs = lr_info['epochs']
                    learning_rates = lr_info['learning_rates']
                    
                    # ì‹œë“œë³„ ìŠ¤íƒ€ì¼ ì°¨ë³„í™”
                    linestyles = ['-', '--', '-.', ':', '-']
                    markers = ['o', 's', '^', 'D', 'v']
                    linestyle = linestyles[seed_idx % len(linestyles)]
                    marker = markers[seed_idx % len(markers)]
                    alpha = 0.7 + 0.3 * (seed_idx / max(1, len(lr_data_list) - 1))
                    
                    label = f'{subset} (seed {seed})'
                    ax.plot(epochs, learning_rates, linestyle=linestyle, color=base_color, 
                           alpha=alpha, label=label, linewidth=2, marker=marker, markersize=4)
            
            ax.set_xlabel('Epoch')
            ax.set_ylabel('Learning Rate')
            ax.set_yscale('log')
            ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left', fontsize=9)
            ax.grid(True, alpha=0.3)
            
            plt.tight_layout()
            
            # í†µí•© ê·¸ë˜í”„ ì €ì¥
            combined_plot_path = os.path.join(plots_dir, f"learning_rate_comparison_all_{time_str}.png")
            plt.savefig(combined_plot_path, dpi=300, bbox_inches='tight')
            plt.close()
            
            print(f"ğŸ“ˆ Learning Rate í†µí•© ë¹„êµ ê·¸ë˜í”„ ì €ì¥ë¨: {combined_plot_path}")
        
        return True
        
    except Exception as e:
        print(f"âš ï¸ Learning Rate ìˆ˜ë ´ ê·¸ë˜í”„ ì €ì¥ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()
        return False

def save_results_to_excel(all_results, mode, time_str):
    """ê²°ê³¼ë¥¼ Excel íŒŒì¼ë¡œ ì €ì¥"""
    try:
        # ê²°ê³¼ ë””ë ‰í† ë¦¬ í™•ì¸
        results_dir = os.path.join("results", "excel_files")
        os.makedirs(results_dir, exist_ok=True)
        
        excel_path = os.path.join(results_dir, f"experiment_results_{time_str}.xlsx")
        
        with pd.ExcelWriter(excel_path, engine='openpyxl') as writer:
            # ë©”ì¸ ê²°ê³¼ ì‹œíŠ¸
            if mode == "1" or mode == "2":  # ì—¬ëŸ¬ ì‹œë“œì— ëŒ€í•œ ê²°ê³¼
                rows = []
                for subset, seed_results in all_results.items():
                    for seed, results in seed_results.items():
                        if results:
                            row = {
                                'Joint_Subset': subset,
                                'Seed': seed,
                                'AUC_ROC': results.get('auc_roc', None),
                                'AUC_PR': results.get('auc_pr', None),
                                'EER': results.get('eer', None),
                                'EER_Threshold': results.get('eer_threshold', None),
                                'Num_Samples': results.get('num_samples', None)
                            }
                            rows.append(row)
                
                if rows:
                    df_main = pd.DataFrame(rows)
                    df_main.to_excel(writer, sheet_name='Main_Results', index=False)
                    
                    # í†µê³„ ìš”ì•½ ì‹œíŠ¸
                    summary_rows = []
                    for subset in all_results.keys():
                        subset_data = df_main[df_main['Joint_Subset'] == subset]
                        if not subset_data.empty:
                            summary_row = {
                                'Joint_Subset': subset,
                                'Num_Seeds': len(subset_data),
                                'AUC_ROC_Mean': subset_data['AUC_ROC'].mean() if 'AUC_ROC' in subset_data.columns else None,
                                'AUC_ROC_Std': subset_data['AUC_ROC'].std() if 'AUC_ROC' in subset_data.columns else None,
                                'AUC_PR_Mean': subset_data['AUC_PR'].mean() if 'AUC_PR' in subset_data.columns else None,
                                'AUC_PR_Std': subset_data['AUC_PR'].std() if 'AUC_PR' in subset_data.columns else None,
                                'EER_Mean': subset_data['EER'].mean() if 'EER' in subset_data.columns else None,
                                'EER_Std': subset_data['EER'].std() if 'EER' in subset_data.columns else None,
                            }
                            summary_rows.append(summary_row)
                    
                    if summary_rows:
                        df_summary = pd.DataFrame(summary_rows)
                        df_summary.to_excel(writer, sheet_name='Summary_Statistics', index=False)
            
            elif mode == "3":  # ë‹¨ì¼ ì‹œë“œ, ì—¬ëŸ¬ ê´€ì ˆ ë¶€ìœ„ì— ëŒ€í•œ ê²°ê³¼
                seed = list(list(all_results.values())[0].keys())[0]
                rows = []
                for subset, seed_results in all_results.items():
                    if seed in seed_results and seed_results[seed]:
                        results = seed_results[seed]
                        row = {
                            'Joint_Subset': subset,
                            'Seed': seed,
                            'AUC_ROC': results.get('auc_roc', None),
                            'AUC_PR': results.get('auc_pr', None),
                            'EER': results.get('eer', None),
                            'EER_Threshold': results.get('eer_threshold', None),
                            'Num_Samples': results.get('num_samples', None)
                        }
                        rows.append(row)
                
                if rows:
                    df_main = pd.DataFrame(rows)
                    df_main.to_excel(writer, sheet_name='Results', index=False)
            
            # í•™ìŠµ ê³¡ì„  ë°ì´í„° ì‹œíŠ¸ (ìˆëŠ” ê²½ìš°)
            learning_curve_rows = []
            for subset, seed_results in all_results.items():
                for seed, results in seed_results.items():
                    if results and 'learning_curves' in results:
                        learning_data = results['learning_curves']
                        max_len = max(
                            len(learning_data.get('epochs', [])),
                            len(learning_data.get('train_loss', [])),
                            len(learning_data.get('val_loss', [])),
                            len(learning_data.get('learning_rates', []))
                        )
                        
                        for i in range(max_len):
                            row = {
                                'Joint_Subset': subset,
                                'Seed': seed,
                                'Step': i + 1,
                                'Epoch': learning_data['epochs'][i] if i < len(learning_data['epochs']) else None,
                                'Train_Loss': learning_data['train_loss'][i] if i < len(learning_data['train_loss']) else None,
                                'Val_Loss': learning_data['val_loss'][i] if i < len(learning_data['val_loss']) else None,
                                'Learning_Rate': learning_data['learning_rates'][i] if i < len(learning_data['learning_rates']) else None
                            }
                            learning_curve_rows.append(row)
            
            if learning_curve_rows:
                df_learning = pd.DataFrame(learning_curve_rows)
                df_learning.to_excel(writer, sheet_name='Learning_Curves', index=False)
            
            # ì‹¤í—˜ ì •ë³´ ì‹œíŠ¸
            info_data = {
                'Parameter': ['Experiment_Date', 'Mode', 'Total_Experiments', 'File_Generated'],
                'Value': [
                    datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
                    f"Mode {mode}",
                    sum(len(seed_results) for seed_results in all_results.values()),
                    time_str
                ]
            }
            df_info = pd.DataFrame(info_data)
            df_info.to_excel(writer, sheet_name='Experiment_Info', index=False)
        
        print(f"ğŸ“Š ê²°ê³¼ê°€ Excel íŒŒì¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤: {excel_path}")
        return True
        
    except Exception as e:
        print(f"âš ï¸ Excel íŒŒì¼ ì €ì¥ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return False

def main():
    # ì‹¤í–‰í•  ê´€ì ˆ ë¶€ìœ„ ëª©ë¡
    subsets = ["all", "arms", "legs", "body", "head", "left_arm", "right_arm", "left_leg", "right_leg","arm+body", "head+body"]
    
    # ì‹¤í–‰í•  ì‹œë“œ ëª©ë¡ (ì—¬ê¸°ì— ì›í•˜ëŠ” ì‹œë“œ ê°’ì„ ì¶”ê°€í•˜ì„¸ìš”)
    seeds = [42,998,75,38,142]
    
    # ì‚¬ìš©ìì—ê²Œ ì–´ë–¤ ëª¨ë“œë¡œ ì‹¤í–‰í• ì§€ ë¬»ê¸°
    print("ì‹¤í—˜ ì‹¤í–‰ ëª¨ë“œë¥¼ ì„ íƒí•˜ì„¸ìš”:")
    print("1. ëª¨ë“  ê´€ì ˆ ë¶€ìœ„ x ëª¨ë“  ì‹œë“œ (ì´ " + str(len(subsets) * len(seeds)) + "ê°œ ì‹¤í—˜)")
    print("2. íŠ¹ì • ê´€ì ˆ ë¶€ìœ„ì— ëŒ€í•´ ì—¬ëŸ¬ ì‹œë“œë¡œ ì‹¤í—˜")
    print("3. ì—¬ëŸ¬ ê´€ì ˆ ë¶€ìœ„ì— ëŒ€í•´ ë‹¨ì¼ ì‹œë“œë¡œ ì‹¤í—˜")
    
    mode = input("ì„ íƒ (1/2/3): ").strip()
    
    # ê²°ê³¼ ì €ì¥ ë”•ì…”ë„ˆë¦¬ ì´ˆê¸°í™”
    all_results = {}
    
    start_time = time.time()
    
    if mode == "1":
        # ëª¨ë“  ì¡°í•© ì‹¤í–‰
        print(f"ğŸ”¬ ëª¨ë“  ê´€ì ˆ ë¶€ìœ„ì™€ ì‹œë“œ ì¡°í•©ìœ¼ë¡œ ì‹¤í—˜ ì‹œì‘ (ì´ {len(subsets) * len(seeds)}ê°œ ì‹¤í—˜)")
        print("=" * 60)
        
        for subset in subsets:
            all_results[subset] = {}
            
            for seed in seeds:
                experiment_key = f"{subset}_seed{seed}"
                success, results = run_experiment(subset, seed)
                
                if success and results:
                    all_results[subset][seed] = results
                else:
                    all_results[subset][seed] = None
    
    elif mode == "2":
        # íŠ¹ì • ê´€ì ˆ ë¶€ìœ„ì— ëŒ€í•´ ì—¬ëŸ¬ ì‹œë“œë¡œ ì‹¤í—˜
        print("ì‚¬ìš©í•  ê´€ì ˆ ë¶€ìœ„ë¥¼ ì„ íƒí•˜ì„¸ìš”:")
        for i, subset in enumerate(subsets, 1):
            print(f"{i}. {subset}")
        
        subset_idx = int(input("ë²ˆí˜¸ ì„ íƒ: ").strip()) - 1
        if 0 <= subset_idx < len(subsets):
            subset = subsets[subset_idx]
            all_results[subset] = {}
            
            print(f"ğŸ”¬ '{subset}' ê´€ì ˆ ë¶€ìœ„ì— ëŒ€í•´ {len(seeds)}ê°œ ì‹œë“œë¡œ ì‹¤í—˜ ì‹œì‘")
            print("=" * 60)
            
            for seed in seeds:
                success, results = run_experiment(subset, seed)
                
                if success and results:
                    all_results[subset][seed] = results
                else:
                    all_results[subset][seed] = None
        else:
            print("âŒ ì˜ëª»ëœ ì„ íƒì…ë‹ˆë‹¤.")
            return
            
    elif mode == "3":
        # ì—¬ëŸ¬ ê´€ì ˆ ë¶€ìœ„ì— ëŒ€í•´ ë‹¨ì¼ ì‹œë“œë¡œ ì‹¤í—˜
        print("ì‚¬ìš©í•  ì‹œë“œë¥¼ ì„ íƒí•˜ì„¸ìš”:")
        for i, seed in enumerate(seeds, 1):
            print(f"{i}. {seed}")
        
        seed_idx = int(input("ë²ˆí˜¸ ì„ íƒ: ").strip()) - 1
        if 0 <= seed_idx < len(seeds):
            seed = seeds[seed_idx]
            
            print(f"ğŸ”¬ {len(subsets)}ê°œ ê´€ì ˆ ë¶€ìœ„ì— ëŒ€í•´ ì‹œë“œ {seed}ë¡œ ì‹¤í—˜ ì‹œì‘")
            print("=" * 60)
            
            for subset in subsets:
                success, results = run_experiment(subset, seed)
                
                if success and results:
                    all_results[subset] = {seed: results}
                else:
                    all_results[subset] = {seed: None}
        else:
            print("âŒ ì˜ëª»ëœ ì„ íƒì…ë‹ˆë‹¤.")
            return
            
    else:
        print("âŒ ì˜ëª»ëœ ì„ íƒì…ë‹ˆë‹¤.")
        return
    
    # ê²°ê³¼ í…Œì´ë¸” ì¶œë ¥
    total_time = time.time() - start_time
    print(f"\n{'='*100}")
    print("ğŸ“Š EXPERIMENT RESULTS")
    print(f"{'='*100}")
    
    # ëª¨ë“œì— ë”°ë¼ ë‹¤ë¥´ê²Œ ê²°ê³¼ ì¶œë ¥
    if mode == "1" or mode == "2":  # ì—¬ëŸ¬ ì‹œë“œì— ëŒ€í•œ ê²°ê³¼
        # ê° ê´€ì ˆ ë¶€ìœ„ë³„ë¡œ ê²°ê³¼ ì¶œë ¥
        for subset, seed_results in all_results.items():
            print(f"\n{'='*50}")
            print(f"ğŸ” {subset.upper()} ë¶€ìœ„ ê²°ê³¼")
            print(f"{'='*50}")
            
            # í—¤ë” ì¶œë ¥
            header = f"{'Seed':<8} {'AUC(ROC)':<10} {'AUC(PR)':<10} {'EER':<8} {'EER_Th':<8} {'Samples':<8}"
            print(header)
            print("-" * len(header))
            
            # ê° ì‹œë“œë³„ ê²°ê³¼ ì¶œë ¥
            for seed, results in seed_results.items():
                if results:
                    auc_roc = f"{results.get('auc_roc', 0):.4f}" if 'auc_roc' in results else "N/A"
                    auc_pr = f"{results.get('auc_pr', 0):.4f}" if 'auc_pr' in results else "N/A"
                    eer = f"{results.get('eer', 0):.4f}" if 'eer' in results else "N/A"
                    eer_th = f"{results.get('eer_threshold', 0):.4f}" if 'eer_threshold' in results else "N/A"
                    samples = str(results.get('num_samples', 'N/A'))
                    
                    row = f"{seed:<8} {auc_roc:<10} {auc_pr:<10} {eer:<8} {eer_th:<8} {samples:<8}"
                else:
                    row = f"{seed:<8} {'FAILED':<10} {'FAILED':<10} {'FAILED':<8} {'FAILED':<8} {'FAILED':<8}"
                
                print(row)
            
            # ì‹œë“œ í‰ê·  ê³„ì‚°
            valid_results = [r for r in seed_results.values() if r]
            if valid_results:
                avg_auc_roc = sum(r.get('auc_roc', 0) for r in valid_results) / len(valid_results)
                avg_auc_pr = sum(r.get('auc_pr', 0) for r in valid_results) / len(valid_results)
                avg_eer = sum(r.get('eer', 0) for r in valid_results) / len(valid_results)
                
                print("-" * len(header))
                print(f"{'í‰ê· ':<8} {avg_auc_roc:.4f}   {avg_auc_pr:.4f}   {avg_eer:.4f}")
            
    elif mode == "3":  # ë‹¨ì¼ ì‹œë“œ, ì—¬ëŸ¬ ê´€ì ˆ ë¶€ìœ„ì— ëŒ€í•œ ê²°ê³¼
        # ì‚¬ìš©í•œ ì‹œë“œ ê°’ ê°€ì ¸ì˜¤ê¸°
        seed = list(list(all_results.values())[0].keys())[0]
        
        # í—¤ë” ì¶œë ¥
        header = f"{'Joint Part':<12} {'AUC(ROC)':<10} {'AUC(PR)':<10} {'EER':<8} {'EER_Th':<8} {'Samples':<8}"
        print(header)
        print("-" * len(header))
        
        # ê° ê´€ì ˆ ë¶€ìœ„ë³„ ê²°ê³¼ ì¶œë ¥
        for subset, seed_results in all_results.items():
            results = seed_results.get(seed)
            
            if results:
                auc_roc = f"{results.get('auc_roc', 0):.4f}" if 'auc_roc' in results else "N/A"
                auc_pr = f"{results.get('auc_pr', 0):.4f}" if 'auc_pr' in results else "N/A"
                eer = f"{results.get('eer', 0):.4f}" if 'eer' in results else "N/A"
                eer_th = f"{results.get('eer_threshold', 0):.4f}" if 'eer_threshold' in results else "N/A"
                samples = str(results.get('num_samples', 'N/A'))
                
                row = f"{subset:<12} {auc_roc:<10} {auc_pr:<10} {eer:<8} {eer_th:<8} {samples:<8}"
            else:
                row = f"{subset:<12} {'FAILED':<10} {'FAILED':<10} {'FAILED':<8} {'FAILED':<8} {'FAILED':<8}"
            
            print(row)
        
        # ì„±ëŠ¥ ë¹„êµ (ì„±ê³µí•œ ì‹¤í—˜ë§Œ)
        successful_results = {}
        for subset, seed_results in all_results.items():
            if seed in seed_results and seed_results[seed]:
                successful_results[subset] = seed_results[seed]
        
        if len(successful_results) > 1:
            print(f"\n{'='*50}")
            print(f"ğŸ† PERFORMANCE RANKING (Seed: {seed})")
            print(f"{'='*50}")
            
            # AUC(ROC) ê¸°ì¤€ ì •ë ¬
            if all('auc_roc' in results for results in successful_results.values()):
                sorted_by_auc = sorted(successful_results.items(), 
                                     key=lambda x: x[1]['auc_roc'], reverse=True)
                
                print("By AUC(ROC):")
                for i, (subset, results) in enumerate(sorted_by_auc, 1):
                    print(f"{i}. {subset:<12}: {results['auc_roc']:.4f}")
            
            # EER ê¸°ì¤€ ì •ë ¬ (ë‚®ì„ìˆ˜ë¡ ì¢‹ìŒ)
            if all('eer' in results for results in successful_results.values()):
                sorted_by_eer = sorted(successful_results.items(), 
                                     key=lambda x: x[1]['eer'])
                
                print(f"\nBy EER (lower is better):")
                for i, (subset, results) in enumerate(sorted_by_eer, 1):
                    print(f"{i}. {subset:<12}: {results['eer']:.4f}")
    
    # Excel íŒŒì¼ë¡œ ê²°ê³¼ ì €ì¥ ë° í•™ìŠµ ê³¡ì„  ê·¸ë˜í”„ ìƒì„±
    time_str = time.strftime("%Y%m%d_%H%M%S")
    
    # Excel íŒŒì¼ ì €ì¥
    excel_success = save_results_to_excel(all_results, mode, time_str)
    
    # í•™ìŠµ ê³¡ì„  ê·¸ë˜í”„ ìƒì„± ë° ì €ì¥
    plot_success = save_learning_curves_plot(all_results, time_str)
    
    # ì„±ëŠ¥ ë¹„êµ ê·¸ë˜í”„ ìƒì„± ë° ì €ì¥
    performance_plot_success = save_performance_comparison_plot(all_results, mode, time_str)
    
    # Learning Rate ì „ìš© ê·¸ë˜í”„ ìƒì„± ë° ì €ì¥  
    lr_plot_success = save_learning_rate_convergence_plot(all_results, time_str)
    
    # ê¸°ì¡´ CSV íŒŒì¼ë„ ìœ ì§€ (í˜¸í™˜ì„±ì„ ìœ„í•´)
    try:
        # ê²°ê³¼ ë””ë ‰í† ë¦¬ í™•ì¸
        results_dir = os.path.join("results", "csv_files")
        os.makedirs(results_dir, exist_ok=True)
        
        # ê²°ê³¼ë¥¼ ë°ì´í„°í”„ë ˆì„ìœ¼ë¡œ ë³€í™˜
        if mode == "1" or mode == "2":  # ì—¬ëŸ¬ ì‹œë“œì— ëŒ€í•œ ê²°ê³¼
            rows = []
            for subset, seed_results in all_results.items():
                for seed, results in seed_results.items():
                    if results:
                        row = {
                            'joint_subset': subset,
                            'seed': seed,
                            'auc_roc': results.get('auc_roc', None),
                            'auc_pr': results.get('auc_pr', None),
                            'eer': results.get('eer', None),
                            'eer_threshold': results.get('eer_threshold', None),
                            'num_samples': results.get('num_samples', None)
                        }
                        rows.append(row)
            
            if rows:
                df = pd.DataFrame(rows)
                csv_path = os.path.join(results_dir, f"experiment_results_{time_str}.csv")
                df.to_csv(csv_path, index=False)
                print(f"ğŸ“„ ê²°ê³¼ê°€ CSV íŒŒì¼ë¡œë„ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤: {csv_path}")
            
        elif mode == "3":  # ë‹¨ì¼ ì‹œë“œ, ì—¬ëŸ¬ ê´€ì ˆ ë¶€ìœ„ì— ëŒ€í•œ ê²°ê³¼
            seed = list(list(all_results.values())[0].keys())[0]
            rows = []
            for subset, seed_results in all_results.items():
                if seed in seed_results and seed_results[seed]:
                    results = seed_results[seed]
                    row = {
                        'joint_subset': subset,
                        'seed': seed,
                        'auc_roc': results.get('auc_roc', None),
                        'auc_pr': results.get('auc_pr', None),
                        'eer': results.get('eer', None),
                        'eer_threshold': results.get('eer_threshold', None),
                        'num_samples': results.get('num_samples', None)
                    }
                    rows.append(row)
            
            if rows:
                df = pd.DataFrame(rows)
                csv_path = os.path.join(results_dir, f"experiment_results_seed{seed}_{time_str}.csv")
                df.to_csv(csv_path, index=False)
                print(f"ğŸ“„ ê²°ê³¼ê°€ CSV íŒŒì¼ë¡œë„ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤: {csv_path}")
    
    except Exception as e:
        print(f"âš ï¸ CSV íŒŒì¼ ì €ì¥ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
    
    print(f"\nâ±ï¸ ì´ ì‹¤í–‰ ì‹œê°„: {total_time:.1f}ì´ˆ")
    print("\nğŸ‰ ëª¨ë“  ì‹¤í—˜ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")

if __name__ == "__main__":
    main()